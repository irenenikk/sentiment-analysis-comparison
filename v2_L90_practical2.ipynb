{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_list(tokens, min_freq=7):\n",
    "    \"\"\" Find bigrams from given text and return in a pandas dataframe. \"\"\"\n",
    "    bigrams = []\n",
    "    for i in range(1, len(tokens)):\n",
    "        bigram = f'{tokens[i-1]} {tokens[i]}'\n",
    "        bigrams += [bigram]\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uni_and_bi_grams(data_folder):\n",
    "    \"\"\" Find unigrams and bigrams in given text and return in a pandas dataframe. \"\"\"\n",
    "    sentiments = ['POS', 'NEG']    \n",
    "    # use lists to avoid calling append in a loop\n",
    "    # unigrams\n",
    "    unigrams = []\n",
    "    unigram_sentiments = []\n",
    "    unigram_file_ids = []\n",
    "    # bigrams\n",
    "    bigrams = []\n",
    "    bigram_sentiments = []\n",
    "    bigram_file_ids = []\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            # find unigrams\n",
    "            new_unigrams = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos']).values[:,0]\n",
    "            unigrams += list(new_unigrams)\n",
    "            unigram_sentiments += [(1 if sent == 'POS' else -1)]*len(new_unigrams)\n",
    "            unigram_file_ids += [f'{sent}-{file[2:5]}']*len(new_unigrams)\n",
    "            # find bigrams\n",
    "            new_bigrams = get_bigram_list(new_unigrams)\n",
    "            bigrams += new_bigrams            \n",
    "            bigram_sentiments += [(1 if sent == 'POS' else -1)]*len(new_bigrams)\n",
    "            bigram_file_ids += [f'{sent}-{file[2:5]}']*len(new_bigrams)\n",
    "    unigram_df = pd.DataFrame(list(zip(unigrams, unigram_sentiments, unigram_file_ids)), columns=['ngram', 'sentiment', 'file_id'])\n",
    "    bigram_df = pd.DataFrame(list(zip(bigrams, bigram_sentiments, bigram_file_ids)), columns=['ngram', 'sentiment', 'file_id'])\n",
    "    return unigram_df, bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams, bigrams, = get_uni_and_bi_grams('data-tagged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_split(data, max_training_id):\n",
    "    mask = data['file_id'].apply(lambda x: int(x[4:7]) <= max_training_id)\n",
    "    return data[mask], data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_unigrams, test_data = single_split(unigrams, 899)\n",
    "training_bigrams, _ = single_split(bigrams, 899)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers for defining the necessary probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_tokenize(content):\n",
    "    \"\"\" Split into unigrams by punctuation and whitespace, then lowercase and remove trailing whitespace\"\"\"\n",
    "    return np.asarray(list(filter(None,((map(lambda x: x, map(str.strip, re.split('(\\W)', content))))))))\n",
    "\n",
    "def bigram_tokenize(content):\n",
    "    \"\"\" Split text into bigrams \"\"\"\n",
    "    tokens = unigram_tokenize(content)\n",
    "    for i in range(1, len(tokens)):\n",
    "        yield f'{tokens[i-1]} {tokens[i]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ngrams(ngrams, sent, min_count, smooth):\n",
    "    counts = ngrams[ngrams['sentiment'] == sent]['ngram'].value_counts()\n",
    "    filtered = counts[counts >= min_count]\n",
    "    voc_size = len(counts)\n",
    "    if smooth:\n",
    "        return (filtered+1)/(sum(filtered)+ngrams['ngram'].nunique())\n",
    "    return filtered/sum(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_probabilites(text, classes, tokenize, data, smooth, min_freq):\n",
    "    class_probs = np.zeros(len(classes))\n",
    "    for i, cl in enumerate(classes):\n",
    "        p = 0\n",
    "        conditioned_counts = preprocess_ngrams(data, cl, min_freq, smooth)\n",
    "        smooth_denom = (data['sentiment']==cl).sum()+data['ngram'].nunique()\n",
    "        for word in tokenize(text):\n",
    "            if word in conditioned_counts.index:\n",
    "                p += np.log(conditioned_counts.loc[word])\n",
    "            # apply smoothing separately if word not present in class\n",
    "            elif smooth:\n",
    "                p += np.log(1/(smooth_denom))\n",
    "        # the prior is the fraction of documents in a specific class\n",
    "        sentiment_files = data[['file_id', 'sentiment']].groupby('file_id').mean()\n",
    "        prior = (sentiment_files['sentiment'] == cl).sum()/len(sentiment_files)\n",
    "        p += np.log(prior)\n",
    "        class_probs[i] = p\n",
    "    return class_probs\n",
    "\n",
    "def naive_binary_bayes(text, unigrams=None, bigrams=None, smooth=True):\n",
    "    \"\"\" Predict the class of a string given unigrams and bigrams. \"\"\"\n",
    "    if unigrams is None and bigrams is None:\n",
    "        raise ValueError('Please choose to use either unigrams or bigrams by providing the data')\n",
    "    # set the binary classification labels\n",
    "    classes = [-1, 1]\n",
    "    class_probs = np.zeros(len(classes))\n",
    "    if unigrams is not None:\n",
    "        class_probs += get_class_probabilites(text, classes, unigram_tokenize, unigrams, smooth, min_freq=1)\n",
    "    if bigrams is not None:\n",
    "        class_probs += get_class_probabilites(text, classes, bigram_tokenize, bigrams, smooth, min_freq=7)\n",
    "    return classes[np.argmax(class_probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('a great movie', bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', unigrams=training_unigrams, bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('i love', unigrams=training_unigrams, bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('i hate', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy(test_data, smooth, unigrams=None, bigrams=None):\n",
    "    \"\"\" Estimate the accuracy over test dataset using given unigrams and bigrams \"\"\"\n",
    "    acc = 0\n",
    "    for file_id, group in test_data.groupby('file_id'):\n",
    "        label = naive_binary_bayes(' '.join(group['ngram'].values), smooth=smooth, unigrams=unigrams, bigrams=bigrams)\n",
    "        # make sure each file is only associated with one sentiment\n",
    "        # otherwise there's a bug in reading of the data\n",
    "        assert(group['sentiment'].nunique() == 1)\n",
    "        acc += (label == group['sentiment'].unique()[0])\n",
    "    return acc/test_data['file_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = estimate_accuracy(test_data, unigrams=training_unigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = estimate_accuracy(test_data, bigrams=training_bigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.855"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = estimate_accuracy(test_data,  unigrams=training_unigrams, bigrams=training_bigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = estimate_accuracy(test_data, unigrams=training_unigrams, smooth=False)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
