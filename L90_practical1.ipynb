{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_data(data, sent, filename):\n",
    "    data['sentiment'] = (1 if sent == 'POS' else -1)\n",
    "    data['file_id'] = f'{sent}-{filename[2:5]}'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigrams(data_folder):\n",
    "    \"\"\" Find unigrams in given text and return in a pandas dataframe. \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            new = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos'])\n",
    "            new['sentiment'] = (1 if sent == sentiments[0] else -1)\n",
    "            new['file_id'] = f'{sent}-{file[2:5]}'\n",
    "            data = data.append(new, sort=False)\n",
    "    return data\n",
    "\n",
    "def get_uni_and_bi_grams2(data_folder):\n",
    "    \"\"\" Find unigrams in given text and return in a pandas dataframe. \"\"\"\n",
    "    unigrams = pd.DataFrame()\n",
    "    bigrams = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            # find unigrams\n",
    "            new_unigrams = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos'])\n",
    "            new_unigrams = tag_data(new_unigrams, sent, file)\n",
    "            unigrams = unigrams.append(new_unigrams, sort=False)\n",
    "            # find bigrams\n",
    "            new_bigrams = find_bigrams(new_unigrams['ngram'].values)\n",
    "            new_bigrams = tag_data(new_bigrams, sent, file)\n",
    "            bigrams = bigrams.append(new_bigrams, sort=False)            \n",
    "    return unigrams, bigrams\n",
    "\n",
    "def get_uni_and_bi_grams(data_folder):\n",
    "    \"\"\" Find unigrams in given text and return in a pandas dataframe. \"\"\"\n",
    "    # use dicts to avoid calling append in a loop\n",
    "    unigrams = []\n",
    "    unigram_sentiments = []\n",
    "    unigram_file_ids = []\n",
    "    bigrams = []\n",
    "    bigram_sentiments = []\n",
    "    bigram_file_ids = []\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            # find unigrams\n",
    "            new_unigrams = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos']).values[:,0]\n",
    "            unigrams += list(new_unigrams)\n",
    "            unigram_sentiments += [(1 if sent == 'POS' else -1)]*len(new_unigrams)\n",
    "            unigram_file_ids += [f'{sent}-{file[2:5]}']*len(new_unigrams)\n",
    "            # find bigrams\n",
    "            new_bigrams = get_bigram_list(new_unigrams)\n",
    "            bigrams += new_bigrams            \n",
    "            bigram_sentiments += [(1 if sent == 'POS' else -1)]*len(new_bigrams)\n",
    "            bigram_file_ids += [f'{sent}-{file[2:5]}']*len(new_bigrams)\n",
    "    unigram_df = pd.DataFrame(list(zip(unigrams, unigram_sentiments, unigram_file_ids)), columns=['ngram', 'sentiment', 'file_id'])\n",
    "    bigram_df = pd.DataFrame(list(zip(bigrams, bigram_sentiments, bigram_file_ids)), columns=['ngram', 'sentiment', 'file_id'])\n",
    "    return unigram_df, bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bigrams(tokens, min_freq=7):\n",
    "    \"\"\" Find bigrams from given text and return in a pandas dataframe. \"\"\"\n",
    "    bigrams = defaultdict(int)\n",
    "    for i in range(1, len(tokens)):\n",
    "        bigram = f'{tokens[i-1]} {tokens[i]}'\n",
    "        bigrams[bigram] += 1\n",
    "    return pd.DataFrame.from_dict(bigrams, orient = 'index')\n",
    "\n",
    "def get_bigram_list(tokens, min_freq=7):\n",
    "    \"\"\" Find bigrams from given text and return in a pandas dataframe. \"\"\"\n",
    "    bigrams = []\n",
    "    for i in range(1, len(tokens)):\n",
    "        bigram = f'{tokens[i-1]} {tokens[i]}'\n",
    "        bigrams += [bigram]\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_tokenize(content):\n",
    "    ''' Split into unigrams by punctuation and whitespace, then lowercase and remove trailing whitespace'''\n",
    "    return np.asarray(list(filter(None,((map(lambda x: x.lower(), map(str.strip, re.split('(\\W)', content))))))))\n",
    "\n",
    "def bigram_tokenize(content):\n",
    "    tokens = unigram_tokenize(content)\n",
    "    for i in range(1, len(tokens)):\n",
    "        yield f'{tokens[i-1]} {tokens[i]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams2(data_folder):\n",
    "    bigrams = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            f = open(os.path.join(review_folder, file), 'r')\n",
    "            content = f.read()\n",
    "            new = find_bigrams(content)\n",
    "            new['file_id'] = int(file[2:5])\n",
    "            new['sentiment'] = (1 if sent == sentiments[0] else -1)\n",
    "            bigrams = bigrams.append(new, sort=False)\n",
    "    return bigrams\n",
    "\n",
    "def get_bigrams(data_folder):\n",
    "    bigrams = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            new = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos'])\n",
    "            new = find_bigrams(new['ngram'].values)\n",
    "            new['file_id'] = f'{sent}-{file[2:5]}'\n",
    "            new['sentiment'] = (1 if sent == sentiments[0] else -1)\n",
    "            bigrams = bigrams.append(new, sort=False)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_text(data_folder):\n",
    "    full_reviews = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            f = open(os.path.join(review_folder, file), 'r')\n",
    "            new = pd.DataFrame()\n",
    "            content = f.read()\n",
    "            new['review'] = [content]\n",
    "            new['file_id'] = int(file[2:5])\n",
    "            new['sentiment'] = (1 if sent == sentiments[0] else -1)\n",
    "            full_reviews = full_reviews.append(new, sort=False)\n",
    "    return full_reviews    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ngrams(ngrams, sent, min_count):\n",
    "    counts = ngrams[ngrams['sentiment'] == sent]['ngram'].value_counts()\n",
    "    filtered = counts[counts >= min_count]\n",
    "    return filtered/sum(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_neg_probabilites2(text, tokenize, data, min_freq):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    pos_ngrams = preprocess_ngrams(data, 1, min_freq) \n",
    "    neg_ngrams = preprocess_ngrams(data, -1, min_freq) \n",
    "    for word in tokenize(text):\n",
    "        if word in pos_ngrams.index:\n",
    "            pos += np.log(pos_ngrams.loc[word])\n",
    "        if word in neg_ngrams.index:\n",
    "            neg += np.log(neg_ngrams.loc[word])\n",
    "    pos_prior = (data['sentiment'] > 0).sum()/len(data)\n",
    "    pos += np.log(pos_prior)\n",
    "    neg += np.log(1-pos_prior)\n",
    "    return pos, neg\n",
    "\n",
    "def naive_binary_bayes2(text, unigrams=None, bigrams=None):\n",
    "    if unigrams is None and bigrams is None:\n",
    "        raise ValueError('Please choose to use either unigrams or bigrams by providing the data')\n",
    "    pos_prob = 0\n",
    "    neg_prob = 0\n",
    "    if unigrams is not None:\n",
    "        pos, neg = get_pos_neg_probabilites(text, unigram_tokenize, unigrams, min_freq=4)\n",
    "        pos_prob += pos\n",
    "        neg_prob += neg\n",
    "    if bigrams is not None:\n",
    "        pos, neg = get_pos_neg_probabilites(text, bigram_tokenize, bigrams, min_freq=7)\n",
    "        pos_prob += pos\n",
    "        neg_prob += neg\n",
    "    #print('pos', pos_prob)\n",
    "    #print('neg', neg_prob)\n",
    "    return 1 if pos_prob > neg_prob else -1\n",
    "\n",
    "def get_pos_neg_probabilites(text, classes, tokenize, data, min_freq):\n",
    "    class_probs = np.zeros(len(classes))\n",
    "    for i, cl in enumerate(classes):\n",
    "        p = 0\n",
    "        conditioned_counts = preprocess_ngrams(data, cl, min_freq) \n",
    "        for word in tokenize(text):\n",
    "            if word in conditioned_counts.index:\n",
    "                p += np.log(conditioned_counts.loc[word])\n",
    "        prior = (data['sentiment'] == cl).sum()/len(data)\n",
    "        p += np.log(prior)\n",
    "        class_probs[i] = p\n",
    "    return class_probs\n",
    "\n",
    "def naive_binary_bayes(text, unigrams=None, bigrams=None):\n",
    "    if unigrams is None and bigrams is None:\n",
    "        raise ValueError('Please choose to use either unigrams or bigrams by providing the data')\n",
    "    max_prob = -1e10000\n",
    "    # set the binary classification labels\n",
    "    classes = [-1, 1]\n",
    "    class_probs = np.zeros(len(classes))\n",
    "    if unigrams is not None:\n",
    "        class_probs += get_pos_neg_probabilites(text, classes, unigram_tokenize, unigrams, min_freq=4)\n",
    "    if bigrams is not None:\n",
    "        class_probs += get_pos_neg_probabilites(text, classes, bigram_tokenize, bigrams, min_freq=7)\n",
    "    #print('pos', pos_prob)\n",
    "    #print('neg', neg_prob)\n",
    "    return classes[np.argmax(class_probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split data into two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_split(data, max_training_id):\n",
    "    mask = data['file_id'].apply(lambda x: int(x[4:7]) <= max_training_id)\n",
    "    return data[mask], data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams, bigrams, = get_uni_and_bi_grams('data-tagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_unigrams, test_data = single_split(unigrams, 899)\n",
    "training_bigrams, _ = single_split(bigrams, 899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this was excellent', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('a great movie', bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('i love', unigrams=training_unigrams, bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('i hate', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy(test_data, unigrams=None, bigrams=None):\n",
    "    acc = 0\n",
    "    i = 0\n",
    "    for file_id, group in test_data.groupby('file_id'):\n",
    "        i += 1\n",
    "        label = naive_binary_bayes(' '.join(group['ngram'].values), unigrams=unigrams, bigrams=bigrams)\n",
    "        print('pred', label)\n",
    "        print('true', group['sentiment'].unique()[0])\n",
    "        #print((label == group['sentiment'].unique()[0]))\n",
    "        assert(group['sentiment'].nunique() == 1)\n",
    "        acc += (label == group['sentiment'].unique()[0])\n",
    "        print(acc/i)\n",
    "    return acc/test_data['file_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.355"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = estimate_accuracy(test_data, unigrams=training_unigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred -1\n",
      "true -1\n",
      "1.0\n",
      "pred -1\n",
      "true -1\n",
      "1.0\n",
      "pred 1\n",
      "true -1\n",
      "0.6666666666666666\n",
      "pred 1\n",
      "true -1\n",
      "0.5\n",
      "pred 1\n",
      "true -1\n",
      "0.4\n",
      "pred -1\n",
      "true -1\n",
      "0.5\n",
      "pred 1\n",
      "true -1\n",
      "0.42857142857142855\n",
      "pred -1\n",
      "true -1\n",
      "0.5\n",
      "pred -1\n",
      "true -1\n",
      "0.5555555555555556\n",
      "pred -1\n",
      "true -1\n",
      "0.6\n",
      "pred 1\n",
      "true -1\n",
      "0.5454545454545454\n",
      "pred 1\n",
      "true -1\n",
      "0.5\n",
      "pred 1\n",
      "true -1\n",
      "0.46153846153846156\n",
      "pred -1\n",
      "true -1\n",
      "0.5\n",
      "pred 1\n",
      "true -1\n",
      "0.4666666666666667\n",
      "pred -1\n",
      "true -1\n",
      "0.5\n",
      "pred 1\n",
      "true -1\n",
      "0.47058823529411764\n",
      "pred 1\n",
      "true -1\n",
      "0.4444444444444444\n",
      "pred -1\n",
      "true -1\n",
      "0.47368421052631576\n",
      "pred 1\n",
      "true -1\n",
      "0.45\n",
      "pred -1\n",
      "true -1\n",
      "0.47619047619047616\n",
      "pred -1\n",
      "true -1\n",
      "0.5\n",
      "pred 1\n",
      "true -1\n",
      "0.4782608695652174\n",
      "pred -1\n",
      "true -1\n",
      "0.5\n",
      "pred -1\n",
      "true -1\n",
      "0.52\n",
      "pred 1\n",
      "true -1\n",
      "0.5\n",
      "pred 1\n",
      "true -1\n",
      "0.48148148148148145\n",
      "pred 1\n",
      "true -1\n",
      "0.4642857142857143\n",
      "pred 1\n",
      "true -1\n",
      "0.4482758620689655\n",
      "pred 1\n",
      "true -1\n",
      "0.43333333333333335\n",
      "pred -1\n",
      "true -1\n",
      "0.45161290322580644\n",
      "pred 1\n",
      "true -1\n",
      "0.4375\n",
      "pred -1\n",
      "true -1\n",
      "0.45454545454545453\n",
      "pred 1\n",
      "true -1\n",
      "0.4411764705882353\n",
      "pred 1\n",
      "true -1\n",
      "0.42857142857142855\n",
      "pred 1\n",
      "true -1\n",
      "0.4166666666666667\n",
      "pred 1\n",
      "true -1\n",
      "0.40540540540540543\n",
      "pred 1\n",
      "true -1\n",
      "0.39473684210526316\n",
      "pred 1\n",
      "true -1\n",
      "0.38461538461538464\n",
      "pred 1\n",
      "true -1\n",
      "0.375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-293-e5137279881f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_bigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-282-b0c4e647218d>\u001b[0m in \u001b[0;36mestimate_accuracy\u001b[0;34m(test_data, unigrams, bigrams)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_binary_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munigrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-291-0b74cbe2ad27>\u001b[0m in \u001b[0;36mnaive_binary_bayes\u001b[0;34m(text, unigrams, bigrams)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mclass_probs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_pos_neg_probabilites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munigram_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbigrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mclass_probs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_pos_neg_probabilites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigram_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m#print('pos', pos_prob)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#print('neg', neg_prob)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-291-0b74cbe2ad27>\u001b[0m in \u001b[0;36mget_pos_neg_probabilites\u001b[0;34m(text, classes, tokenize, data, min_freq)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mconditioned_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconditioned_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-278-54a1ab959826>\u001b[0m in \u001b[0;36mpreprocess_ngrams\u001b[0;34m(ngrams, sent, min_count)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[1;32m   1390\u001b[0m             \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m         )\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                 \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0minferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minferred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"integer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc = estimate_accuracy(test_data, bigrams=training_bigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = estimate_accuracy(test_data,  unigrams=training_unigrams, bigrams=training_bigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
