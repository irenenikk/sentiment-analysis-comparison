{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.stats import binom\n",
    "from functools import reduce\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_list(tokens, min_freq=7):\n",
    "    \"\"\" Find bigrams from given text and return in a pandas dataframe. \"\"\"\n",
    "    bigrams = []\n",
    "    for i in range(1, len(tokens)):\n",
    "        bigram = f'{tokens[i-1]} {tokens[i]}'\n",
    "        bigrams += [bigram]\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uni_and_bi_grams(data_folder):\n",
    "    \"\"\" Find unigrams and bigrams in given text and return in a pandas dataframe. \"\"\"\n",
    "    sentiments = ['POS', 'NEG']    \n",
    "    # use lists to avoid calling append in a loop\n",
    "    # unigrams\n",
    "    unigrams = []\n",
    "    unigram_sentiments = []\n",
    "    unigram_file_ids = []\n",
    "    unigram_file_nos = []\n",
    "    # bigrams\n",
    "    bigrams = []\n",
    "    bigram_sentiments = []\n",
    "    bigram_file_ids = []\n",
    "    niigram_file_nos = []    \n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            # find unigrams\n",
    "            new_unigrams = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos']).values[:,0]\n",
    "            unigrams += list(new_unigrams)\n",
    "            unigram_sentiments += [(1 if sent == 'POS' else -1)]*len(new_unigrams)\n",
    "            unigram_file_ids += [f'{sent}-{file[2:5]}']*len(new_unigrams)\n",
    "            unigram_file_nos += [int(file[2:5])]*len(new_unigrams)\n",
    "            # find bigrams\n",
    "            new_bigrams = get_bigram_list(new_unigrams)\n",
    "            bigrams += new_bigrams            \n",
    "            bigram_sentiments += [(1 if sent == 'POS' else -1)]*len(new_bigrams)\n",
    "            bigram_file_ids += [f'{sent}-{file[2:5]}']*len(new_bigrams)\n",
    "            bigram_file_nos += [int(file[2:5])]*len(new_bigrams)\n",
    "    unigram_df = pd.DataFrame(list(zip(unigrams, unigram_sentiments, unigram_file_ids, unigram_file_nos)), columns=['ngram', 'sentiment', 'file_id', 'file_no'])\n",
    "    bigram_df = pd.DataFrame(list(zip(bigrams, bigram_sentiments, bigram_file_ids, bigram_file_nos)), columns=['ngram', 'sentiment', 'file_id', 'file_no'])\n",
    "    return unigram_df, bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams, bigrams, = get_uni_and_bi_grams('data-tagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers for defining the necessary probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_tokenize(content):\n",
    "    \"\"\" Split into unigrams by punctuation and whitespace, then lowercase and remove trailing whitespace\"\"\"\n",
    "    return np.asarray(list(filter(None,((map(lambda x: x, map(str.strip, re.split('(\\W)', content))))))))\n",
    "\n",
    "def bigram_tokenize(content):\n",
    "    \"\"\" Split text into bigrams \"\"\"\n",
    "    tokens = unigram_tokenize(content)\n",
    "    for i in range(1, len(tokens)):\n",
    "        yield f'{tokens[i-1]} {tokens[i]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ngrams(ngrams, sent, min_count, smooth):\n",
    "    counts = ngrams[ngrams['sentiment'] == sent]['ngram'].value_counts()\n",
    "    filtered = counts[counts >= min_count]\n",
    "    voc_size = len(counts)\n",
    "    if smooth:\n",
    "        return (filtered+1)/(sum(filtered)+ngrams['ngram'].nunique())\n",
    "    return filtered/sum(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_probabilites(text, classes, tokenize, data, smooth, min_freq):\n",
    "    class_probs = np.zeros(len(classes))\n",
    "    for i, cl in enumerate(classes):\n",
    "        p = 0\n",
    "        conditioned_counts = preprocess_ngrams(data, cl, min_freq, smooth)\n",
    "        smooth_denom = (data['sentiment']==cl).sum()+data['ngram'].nunique()\n",
    "        for word in tokenize(text):\n",
    "            if word in conditioned_counts.index:\n",
    "                p += np.log(conditioned_counts.loc[word])\n",
    "            # apply smoothing separately if word not present in class\n",
    "            elif smooth:\n",
    "                p += np.log(1/(smooth_denom))\n",
    "        # the prior is the fraction of documents in a specific class\n",
    "        sentiment_files = data[['file_id', 'sentiment']].groupby('file_id').mean()\n",
    "        prior = (sentiment_files['sentiment'] == cl).sum()/len(sentiment_files)\n",
    "        p += np.log(prior)\n",
    "        class_probs[i] = p\n",
    "    return class_probs\n",
    "\n",
    "def naive_binary_bayes(text, unigrams=None, bigrams=None, smooth=True):\n",
    "    \"\"\" Predict the class of a string given unigrams and bigrams. \"\"\"\n",
    "    if unigrams is None and bigrams is None:\n",
    "        raise ValueError('Please choose to use either unigrams or bigrams by providing the data')\n",
    "    # set the binary classification labels\n",
    "    classes = [-1, 1]\n",
    "    class_probs = np.zeros(len(classes))\n",
    "    if unigrams is not None:\n",
    "        class_probs += get_class_probabilites(text, classes, unigram_tokenize, unigrams, smooth, min_freq=4)\n",
    "    if bigrams is not None:\n",
    "        class_probs += get_class_probabilites(text, classes, bigram_tokenize, bigrams, smooth, min_freq=7)\n",
    "    return classes[np.argmax(class_probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveB:\n",
    "    \n",
    "    def preprocess_ngrams(ngrams, sent, min_count, smooth):\n",
    "        counts = ngrams[ngrams['sentiment'] == sent]['ngram'].value_counts()\n",
    "        filtered = counts[counts >= min_count]\n",
    "        voc_size = len(counts)\n",
    "        if smooth:\n",
    "            return (filtered+1)/(sum(filtered)+ngrams['ngram'].nunique())\n",
    "        return filtered/sum(filtered)    \n",
    "    \n",
    "    def __init__(self, classes, unigrams=None, bigrams=None):\n",
    "        self.unigrams = unigrams\n",
    "        self.bigrams = bigrams\n",
    "        self.classes = classes\n",
    "        \n",
    "    def get_class_probabilites(self, text, tokenize, data, smooth, min_freq):\n",
    "        class_probs = np.zeros(len(self.classes))\n",
    "        for i, cl in enumerate(self.classes):\n",
    "            p = 0\n",
    "            conditioned_counts = preprocess_ngrams(data, cl, min_freq, smooth)\n",
    "            smooth_denom = (data['sentiment']==cl).sum()+data['ngram'].nunique()\n",
    "            for word in tokenize(text):\n",
    "                if word in conditioned_counts.index:\n",
    "                    p += np.log(conditioned_counts.loc[word])\n",
    "                # apply smoothing separately if word not present in class\n",
    "                elif smooth:\n",
    "                    p += np.log(1/(smooth_denom))\n",
    "            # the prior is the fraction of documents in a specific class\n",
    "            sentiment_files = data[['file_id', 'sentiment']].groupby('file_id').mean()\n",
    "            prior = (sentiment_files['sentiment'] == cl).sum()/len(sentiment_files)\n",
    "            p += np.log(prior)\n",
    "            class_probs[i] = p\n",
    "        return class_probs    \n",
    "    \n",
    "    def predict2(self, text, smooth=True):\n",
    "        # set the binary classification labels\n",
    "        class_probs = np.zeros(len(self.classes))\n",
    "        if self.unigrams is not None:\n",
    "            class_probs += self.get_class_probabilites(text, unigram_tokenize, self.unigrams, smooth, min_freq=4)\n",
    "        if self.bigrams is not None:\n",
    "            class_probs += self.get_class_probabilites(text, bigram_tokenize, self.bigrams, smooth, min_freq=7)\n",
    "        return self.classes[np.argmax(class_probs)]\n",
    "    \n",
    "    def predict(self, text, training_data_files, smooth=True):\n",
    "        # set the binary classification labels\n",
    "        class_probs = np.zeros(len(self.classes))\n",
    "        if self.unigrams is not None:\n",
    "            class_probs += self.get_class_probabilites(text, unigram_tokenize, self.unigrams[self.unigrams['file_no'].isin(training_data_files)], smooth, min_freq=4)\n",
    "        if self.bigrams is not None:\n",
    "            class_probs += self.get_class_probabilites(text, bigram_tokenize, self.bigrams[self.bigrams['file_no'].isin(training_data_files)], smooth, min_freq=7)\n",
    "        return self.classes[np.argmax(class_probs)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_naiveB = NaiveB([-1, 1], unigrams=unigrams)\n",
    "bi_naiveB = NaiveB([-1, 1], bigrams=bigrams)\n",
    "uni_bi_naiveB = NaiveB([-1, 1], unigrams=unigrams, bigrams=bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_naiveB.predict('a great movie', list(range(899)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_naiveB.predict('this is a very bad movie', uni_training_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy2(test_data, unigrams=None, bigrams=None):\n",
    "    \"\"\" Estimate the accuracy over test dataset using given unigrams and bigrams \"\"\"\n",
    "    acc = 0\n",
    "    for file_id, group in test_data.groupby('file_id'):\n",
    "        label = naive_binary_bayes(' '.join(group['ngram'].values), smooth=smooth, unigrams=unigrams, bigrams=bigrams)\n",
    "        # make sure each file is only associated with one sentiment\n",
    "        # otherwise there's a bug in reading of the data\n",
    "        assert(group['sentiment'].nunique() == 1)\n",
    "        acc += (label == group['sentiment'].unique()[0])\n",
    "    return acc/test_data['file_id'].nunique()\n",
    "\n",
    "def estimate_accuracy(test_data, training_data_files, naive_B, smooth):\n",
    "    \"\"\" Estimate the accuracy over test dataset using given unigrams and bigrams \"\"\"\n",
    "    acc = 0\n",
    "    for file_id, group in test_data.groupby('file_id'):\n",
    "        label = naive_B.predict(' '.join(group['ngram'].values), training_data_files, smooth=smooth)\n",
    "        # make sure each file is only associated with one sentiment\n",
    "        # otherwise there's a bug in reading of the data\n",
    "        assert(group['sentiment'].nunique() == 1)\n",
    "        acc += (label == group['sentiment'].unique()[0])\n",
    "    return acc/test_data['file_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 15s, sys: 28.3 s, total: 4min 43s\n",
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "estimate_accuracy(test_data, list(range(899)), uni_naiveB, smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_accuracy(test_data, list(range(899)), bi_naiveB, smooth=True)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_accuracy(test_data, list(range(899)), uni_bi_naiveB, smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_accuracy(test_data, list(range(899)), uni_naiveB, smooth=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p_value(N, k, q):\n",
    "    res = 0\n",
    "    for i in range(k):\n",
    "        res += binom.pmf(i, N, q)\n",
    "    return 2*res\n",
    "\n",
    "def sign_test(data, system_A, system_B, n=10):\n",
    "    plus, minus, null = 0, 0, 0\n",
    "    for i in range(n):\n",
    "        print('test', i+1, 'out of', n)\n",
    "        a = system_A(data)\n",
    "        b = system_B(data)\n",
    "        if a > b:\n",
    "            plus += 1\n",
    "        elif a < b:\n",
    "            minus += 1\n",
    "        else:\n",
    "            null += 1\n",
    "    N = 2*math.ceil(null/2)+plus+minus\n",
    "    k = math.ceil(null/2)+min(plus, minus)\n",
    "    return calculate_p_value(N, k, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_unigram_bayes(data):\n",
    "    uni_naiveB = NaiveB([-1, 1], unigrams=unigrams)\n",
    "    return estimate_accuracy(data, unigrams=training_unigrams, smooth=True)\n",
    "\n",
    "def unsmoothed_unigram_bayes(data):\n",
    "    return estimate_accuracy(data, unigrams=training_unigrams, smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0 out of 10\n",
      "test 1 out of 10\n",
      "test 2 out of 10\n",
      "test 3 out of 10\n",
      "test 4 out of 10\n",
      "test 5 out of 10\n",
      "test 6 out of 10\n",
      "test 7 out of 10\n",
      "test 8 out of 10\n",
      "test 9 out of 10\n",
      "CPU times: user 58min 32s, sys: 6min 39s, total: 1h 5min 12s\n",
      "Wall time: 1h 10min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "p_value = sign_test(test_data, smoothed_unigram_bayes, unsmoothed_unigram_bayes)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_variance(data):\n",
    "    mean = np.mean(data)\n",
    "    return np.sum(np.square(data-mean))\n",
    "\n",
    "def cross_validate(naive_B, data, folds):\n",
    "    file_amount = data['file_no'].nunique()\n",
    "    indx = np.arange(0, file_amount, folds)\n",
    "    scores = np.zeros(folds)\n",
    "    for f in range(folds):\n",
    "        test_data_mask = data['file_no'].isin(indx+f)\n",
    "        training_file_ids = data[~test_data_mask]['file_no'].unique()\n",
    "        test_data = data[test_data_mask]\n",
    "        acc = estimate_accuracy(test_data, training_file_ids, naive_B, smooth=True)\n",
    "        print(acc)\n",
    "        scores[f] = acc\n",
    "    return np.mean(scores), variance(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "acc_mean, acc_var = cross_validate(uni_naiveB, unigrams, 10)\n",
    "# accuracies\n",
    "# results\n",
    "# mean: 81.10\n",
    "# variance: 0.0070224999999999845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:naive-bayes]",
   "language": "python",
   "name": "conda-env-naive-bayes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
