{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_data(data, sent, filename):\n",
    "    data['sentiment'] = (1 if sent == 'POS' else -1)\n",
    "    data['file_id'] = f'{sent}-{filename[2:5]}'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigrams(data_folder):\n",
    "    \"\"\" Find unigrams in given text and return in a pandas dataframe. \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            new = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos'])\n",
    "            new['sentiment'] = (1 if sent == sentiments[0] else -1)\n",
    "            new['file_id'] = f'{sent}-{file[2:5]}'\n",
    "            data = data.append(new, sort=False)\n",
    "    return data\n",
    "\n",
    "def get_uni_and_bi_grams2(data_folder):\n",
    "    \"\"\" Find unigrams in given text and return in a pandas dataframe. \"\"\"\n",
    "    unigrams = pd.DataFrame()\n",
    "    bigrams = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            # find unigrams\n",
    "            new_unigrams = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos'])\n",
    "            new_unigrams = tag_data(new_unigrams, sent, file)\n",
    "            unigrams = unigrams.append(new_unigrams, sort=False)\n",
    "            # find bigrams\n",
    "            new_bigrams = find_bigrams(new_unigrams['ngram'].values)\n",
    "            new_bigrams = tag_data(new_bigrams, sent, file)\n",
    "            bigrams = bigrams.append(new_bigrams, sort=False)            \n",
    "    return unigrams, bigrams\n",
    "\n",
    "def get_uni_and_bi_grams(data_folder):\n",
    "    \"\"\" Find unigrams in given text and return in a pandas dataframe. \"\"\"\n",
    "    # use dicts to avoid calling append in a loop\n",
    "    unigrams = []\n",
    "    unigram_sentiments = []\n",
    "    unigram_file_ids = []\n",
    "    bigrams = []\n",
    "    bigram_sentiments = []\n",
    "    bigram_file_ids = []\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            # find unigrams\n",
    "            new_unigrams = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos']).values[:,0]\n",
    "            unigrams += list(new_unigrams)\n",
    "            unigram_sentiments += [(1 if sent == 'POS' else -1)]*len(new_unigrams)\n",
    "            unigram_file_ids += [f'{sent}-{file[2:5]}']*len(new_unigrams)\n",
    "            # find bigrams\n",
    "            new_bigrams = get_bigram_list(new_unigrams)\n",
    "            bigrams += new_bigrams            \n",
    "            bigram_sentiments += [(1 if sent == 'POS' else -1)]*len(new_bigrams)\n",
    "            bigram_file_ids += [f'{sent}-{file[2:5]}']*len(new_bigrams)\n",
    "    unigram_df = pd.DataFrame(list(zip(unigrams, unigram_sentiments, unigram_file_ids)), columns=['ngram', 'sentiment', 'file_id'])\n",
    "    bigram_df = pd.DataFrame(list(zip(bigrams, bigram_sentiments, bigram_file_ids)), columns=['ngram', 'sentiment', 'file_id'])\n",
    "    return unigram_df, bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bigrams(tokens, min_freq=7):\n",
    "    \"\"\" Find bigrams from given text and return in a pandas dataframe. \"\"\"\n",
    "    bigrams = defaultdict(int)\n",
    "    for i in range(1, len(tokens)):\n",
    "        bigram = f'{tokens[i-1]} {tokens[i]}'\n",
    "        bigrams[bigram] += 1\n",
    "    return pd.DataFrame.from_dict(bigrams, orient = 'index')\n",
    "\n",
    "def get_bigram_list(tokens, min_freq=7):\n",
    "    \"\"\" Find bigrams from given text and return in a pandas dataframe. \"\"\"\n",
    "    bigrams = []\n",
    "    for i in range(1, len(tokens)):\n",
    "        bigram = f'{tokens[i-1]} {tokens[i]}'\n",
    "        bigrams += [bigram]\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_tokenize(content):\n",
    "    ''' Split into unigrams by punctuation and whitespace, then lowercase and remove trailing whitespace'''\n",
    "    return np.asarray(list(filter(None,((map(lambda x: x.lower(), map(str.strip, re.split('(\\W)', content))))))))\n",
    "\n",
    "def bigram_tokenize(content):\n",
    "    tokens = unigram_tokenize(content)\n",
    "    for i in range(1, len(tokens)):\n",
    "        yield f'{tokens[i-1]} {tokens[i]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams2(data_folder):\n",
    "    bigrams = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            f = open(os.path.join(review_folder, file), 'r')\n",
    "            content = f.read()\n",
    "            new = find_bigrams(content)\n",
    "            new['file_id'] = int(file[2:5])\n",
    "            new['sentiment'] = (1 if sent == sentiments[0] else -1)\n",
    "            bigrams = bigrams.append(new, sort=False)\n",
    "    return bigrams\n",
    "\n",
    "def get_bigrams(data_folder):\n",
    "    bigrams = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            new = pd.read_csv(os.path.join(review_folder, file), sep='\\t', header=None, names=['ngram', 'pos'])\n",
    "            new = find_bigrams(new['ngram'].values)\n",
    "            new['file_id'] = f'{sent}-{file[2:5]}'\n",
    "            new['sentiment'] = (1 if sent == sentiments[0] else -1)\n",
    "            bigrams = bigrams.append(new, sort=False)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_text(data_folder):\n",
    "    full_reviews = pd.DataFrame()\n",
    "    sentiments = ['POS', 'NEG']\n",
    "    for sent in sentiments:\n",
    "        review_folder = f'{data_folder}/{sent}'\n",
    "        for file in os.listdir(review_folder):\n",
    "            f = open(os.path.join(review_folder, file), 'r')\n",
    "            new = pd.DataFrame()\n",
    "            content = f.read()\n",
    "            new['review'] = [content]\n",
    "            new['file_id'] = int(file[2:5])\n",
    "            new['sentiment'] = (1 if sent == sentiments[0] else -1)\n",
    "            full_reviews = full_reviews.append(new, sort=False)\n",
    "    return full_reviews    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ngrams(ngrams, sent, min_count):\n",
    "    counts = ngrams[ngrams['sentiment'] == sent]['ngram'].value_counts()\n",
    "    filtered = counts[counts >= min_count]\n",
    "    return filtered/sum(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_neg_probabilites(text, tokenize, data, min_freq):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    pos_ngrams = preprocess_ngrams(data, 1, min_freq) \n",
    "    neg_ngrams = preprocess_ngrams(data, -1, min_freq) \n",
    "    for word in tokenize(text):\n",
    "        if word in pos_ngrams.index:\n",
    "            pos += np.log(pos_ngrams.loc[word])\n",
    "        if word in neg_ngrams.index:\n",
    "            neg += np.log(neg_ngrams.loc[word])\n",
    "    pos_prior = (data['sentiment'] > 0).sum()/len(data)\n",
    "    pos += np.log(pos_prior)\n",
    "    neg += np.log(1-pos_prior)\n",
    "    return pos, neg\n",
    "\n",
    "def naive_binary_bayes(text, unigrams=None, bigrams=None):\n",
    "    if unigrams is None and bigrams is None:\n",
    "        raise ValueError('Please choose to use either unigrams or bigrams by providing the data')\n",
    "    pos_prob = 0\n",
    "    neg_prob = 0\n",
    "    if unigrams is not None:\n",
    "        pos, neg = get_pos_neg_probabilites(text, unigram_tokenize, unigrams, min_freq=4)\n",
    "        pos_prob += pos\n",
    "        neg_prob += neg\n",
    "    if bigrams is not None:\n",
    "        pos, neg = get_pos_neg_probabilites(text, bigram_tokenize, bigrams, min_freq=7)\n",
    "        pos_prob += pos\n",
    "        neg_prob += neg\n",
    "    #print('pos', pos_prob)\n",
    "    #print('neg', neg_prob)\n",
    "    return 1 if pos_prob > neg_prob else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split data into two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_split(data, max_training_id):\n",
    "    mask = data['file_id'].apply(lambda x: int(x[4:7]) <= max_training_id)\n",
    "    return data[mask], data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams, bigrams, = get_uni_and_bi_grams('data-tagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_unigrams, test_data = single_split(unigrams, 899)\n",
    "training_bigrams, _ = single_split(bigrams, 899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this was excellent', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('a great movie', bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('this is a very bad movie', bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('i love', unigrams=training_unigrams, bigrams=training_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_binary_bayes('i hate', unigrams=training_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy(test_data, unigrams=None, bigrams=None):\n",
    "    acc = 0\n",
    "    i = 0\n",
    "    for file_id, group in test_data.groupby('file_id'):\n",
    "        i += 1\n",
    "        label = naive_binary_bayes(' '.join(group['ngram'].values), unigrams=unigrams, bigrams=bigrams)\n",
    "        #print('pred', label)\n",
    "        #print('true', group['sentiment'].unique()[0])\n",
    "        #print((label == group['sentiment'].unique()[0]))\n",
    "        assert(group['sentiment'].nunique() == 1)\n",
    "        acc += (label == group['sentiment'].unique()[0])\n",
    "        #print(acc/i)\n",
    "    return acc/test_data['file_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.355"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = estimate_accuracy(test_data, unigrams=training_unigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = estimate_accuracy(test_data, bigrams=training_bigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = estimate_accuracy(test_data,  unigrams=training_unigrams, bigrams=training_bigrams)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = preprocess_ngrams(unigrams, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos[10:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-cd84498fe910>\u001b[0m in \u001b[0;36mget_uni_and_bi_grams\u001b[0;34m(data_folder)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mnew_bigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_bigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_unigrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mnew_bigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_bigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_bigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0munigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7136\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7137\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7138\u001b[0;31m             \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7139\u001b[0m         )\n\u001b[1;32m   7140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m   5268\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5239\u001b[0m         \"\"\"\n\u001b[1;32m   5240\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5241\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5249\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5252\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5191\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5192\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5194\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unigrams, bigrams = get_uni_and_bi_grams('data-tagged/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_bigrams()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
